---
title: "8.1.3 CUBE 설치 - Cluster on GCP"
excerpt: ""
permalink: /docs/ko/8.1.1.3/
redirect_from:
  - /theme-setup/
toc: true
toc_sticky: true
---

### GCP 인스턴스 생성

* **이름(Name):**  
인스턴스 이름을 부여합니다.

* **지역(Region):**  
지역은 리소스를 실행할 수 있는 특정 지리적 위치입니다.

* **영역(Zone):**  
영역은 지역 내의 격리된 위치입니다. 영역은 사용할 수 있는 컴퓨팅 리소스와 데이터를 저장하고 사용할 위치를 결정합니다.

* **머신 유형(Machine type):**  
맞춤설정을 클릭하여 코어, 메모리, CPU를 선택합니다.

* **부팅 디스크(Boot disk):**  
각 인스턴스에는 부팅을 위한 디스크가 필요합니다. 이미지나 스냅샷을 선택하여 새 부팅 디스크를 생성하거나 기존 디스크를 인스턴스에 연결하세요.  
이 사용 설명서에서는 CentOS 7 사용합니다.

* **ID 및 API 액세스(Identity and API access):**  
생성한 서비스 계정을 선택합니다.  
VM에서 실행되는 애플리케이션은 서비스 계정을 사용하여 Google Cloud API를 호출합니다. 사용할 서비스 계정과 허용할 API 액세스 수준을 선택하세요. [자세히 알아보기](https://cloud.google.com/compute/docs/access/create-enable-service-accounts-for-instances?hl)

    ![gke-create-instance-1]({{ site.baseurl }}/assets/KR/{{ site.version }}/GKE/gke-create-instance-1.png)

 **Management, security, disks, networking, sole tenancy 확장 섹션**을 활성화 해서 아래 설정을 합니다.
 
* **디스크(Disks) 설정**

    * Add new disk를 선택 합니다.

        * 노드에 필요한 디스크 사양을 설정 합니다.

        ![gke-create-instance-disk-1]({{ site.baseurl }}/assets/KR/{{ site.version }}/GKE/gke-create-instance-disk-1.png)

* **네트워크(Networking) 설정**  
네트워크는 인스턴스에서 액세스할 수 있는 네트워크 트래픽을 결정합니다.

    * **Network tags(네트워크 태그):**  
    네트워크 태그를 할당하여 특정 VM 인스턴스에 방화벽 규칙을 적용합니다.

    * **Network interfaces(네트워크 인터페이스)**

        * **Network(네트워크):**  
        목록에서 VPC network에서 생성한 VPC를 선택합니다.

        * **Subnetwork(하위 네트워크):**  
        목록에서 VPC network에서 생성한 subnet을 선택합니다.

        * **Primary internal IP(기본 내부 IP):**  
        임시의 경우 인스턴스를 다시 시작해도 내부 IP가 변경되지 않지만 인스턴스를 삭제하고 다시 만들면 내부 IP가 변경됩니다.  
        '임시(자동)'를 선택하여 하위 네트워크 범위의 주소를 할당하거나 '임시(커스텀)'를 선택하여 직접 입력하세요.  
        **인스턴스를 삭제하고 다시 만들 때 IP를 유지하려면 고정 내부 IP 주소를 선택하거나 만드세요.**  
        [자세히 알아보기](https://cloud.google.com/compute/docs/subnetworks)

            ![gke-create-instance-network-2]({{ site.baseurl }}/assets/KR/{{ site.version }}/GKE/gke-create-instance-network-2.png)

        * done(완료)**를 선택합니다.

* **Create(만들기)**를 선택합니다.

### GCP VPC network 구성

### Node 방화벽 설정

### Node SSH 연결

### shared-storage 노드에 NFS 서버 설치

### docker 설치

    * 18.06.1 version을 설치 해야 한다.

    * Start the Docker daemon  
    참조 : [Control Docker with systemd](https://docs.docker.com/config/daemon/systemd/)

        * 재부팅시에도 서비스가 start 될수 있도록 등록 한다.

            ```
            systemctl enable docker
            ```

        * 서비스를 start 한다.

            ```
            systemctl start docker
            ```

        * 아래 명령으로 docker daemon start(client , server)를 확인할 수 있다

            ```
            docker version
            ```

### cube.toml 설정

```
[cube]
version = "1.13.1-r2"
provider = false
cluster-name = "cube-tc-gcp-cluster"
cluster-description = "This is test cluster"
cluster-type = "small"
cluster-id = "cube-tc-gcp-cluster-id"
alert-language = "ko"


[kubenetes]
service-cidr = "10.96.0.0/12"
pod-cidr = "10.10.0.0/16"

  [kubenetes.etcd]
  ip = [
    "192.168.1.2",
    "192.168.1.3",
    "192.168.1.4",
    "192.168.1.5"
  ]

[node-pool]
data-dir = "/data"

  [node-pool.provider]
  name = "gcp"
  location = "default"

  [node-pool.security]
  ssh-user-id = "cloud"
  private-key-path = "/root/cubetest/cert-ssh/"
  key-path = "cocktail-cube-tc-ssh"

  [node-pool.master]
  name = "master"
  ip = [
    "192.168.1.2",
    "192.168.1.3"
  ]
  loadbalancer-ip = ""
  ingress-host = ""
  node-port-url = ""
  node-portrange = "30000-32767"

  [[node-pool.nodes]]
  name = "default"
  ip = [
    "192.168.1.4",
    "192.168.1.5"
  ]

[enterprise-product]
install = true
release-name = "cocktail"
https = false
  [enterprise-product.cert-file]
  ssl-certificate = ""
  ssl-certificate-key = ""

[addon]
install = true

[shared-storage]
install = true
name = "shared"
storage-ip = "192.168.1.5"
storage-mount-dir = "/storage"
storage-volume-size = 100

[private-registry]
install = true
name = "harbor"
registry-ip = "192.168.1.4"
data-dir = "/data"
public-cert = false
  [private-registry.cert-file]
  ssl-certificate = ""
  ssl-certificate-key = ""
```


### error

#### 1. 

```
[root@cocktail-cube-tc-node-3 cubetest]# ./cube create
Setup cube cluster ...
ERROR! Syntax Error while loading YAML.
expected <block end>, but found '<scalar>'

The error appears to have been in '/cube/cubescripts/roles/registry/tasks/main.yml': line 89, column 38, but may
be elsewhere in the file depending on the exact syntax problem.

The offending line appears to be:

args:
chdir: '{{ harbor_install_dir }}'s
^ here
We could be wrong, but this one looks like it might be an issue with
missing quotes.  Always quote template expression brackets when they
start a value. For instance:

with_items:
- {{ foo }}

Should be written as:

with_items:
- "{{ foo }}"
Setup cube cluster Done. (3s)
```

에러 발생후 에러 조치 안내 없이 Installation Completed. 로 나온다.

* 햬결 :

    syntex 에러 ansible 에서 싱글 쿼터를 쓰면 안된다.


### 설치노드에서 내부망 ssh 접속 확인 필요 

* RSA Key pail 퍼미션이 잘못 되어 있으면 에러는 나지만 안내 메세지 없이 Installation Completed 를 출력 한다.


### ssh 에러가 나면서 계속 진행 된다.

```
  Common setup for instances ... - Failed to connect to the host via ssh: Shared connection to 192.168.1.3 closed.
[WARNING]: sftp transfer mechanism failed on [192.168.1.6]. Use
ANSIBLE_DEBUG=1 to see detailed information
msg: 'Failed to connect to the host via ssh: '
msg: 'Failed to connect to the host via ssh: '
Failed to connect to the host via ssh: ssh: connect to host 192.168.1.5 port 22: Connection refused
   Common setup for instances ... \ [WARNING]: scp transfer mechanism failed on [192.168.1.6]. Use ANSIBLE_DEBUG=1
to see detailed information
   Common setup for instances is done
```

### 예외상황 체크 리스트 필요

1. master 2개 이상일때 lb 체크 필수 항목


### 로그인 체크 cube cli
아래 명령을 통해 시스템 계정으로 로그인 한다.

```
./cube login -u <cocktail url> -i <system ID> -p <passworld> -s <system account>
```
1. id , 패스워드 노출 문제 있음.

2. login fail 메세지 : User id not found (CCUS1001000).  
세분화 메세지 id, password, system account 필요


### 새로운 폴더 생성후 설치 이어갈때

    ```
    export PATH=$PATH:~/cubetest
    ```

    ```
    mkdir cubetest1
    ``

    ```
    안내 메세지 자세한 내용 필요.
    [root@cocktail-cube-tc-node-3 cubetest1]# cube cluster register
    open generated/acloud-client-kubeconfig: no such file or directory
    [root@cocktail-cube-tc-node-3 cubetest1]# cube cluster list
    Please login and use.
    ```


* 에러 내용

```
[root@cocktail-cube-tc-node-3 cubetest1]# cube login -u http://192.168.1.2:30000 -i hong@gmail.com -p H0 ng@c0rns0ft -s CUBE-TC
(conn=6905) Could not send query: unexpected end of stream, read 0 bytes from 4 (CDCM2031000)
```

### cube update

* cube.toml 변경

```
[root@cocktail-cube-tc-node-3 cubetest]# cat cube.toml
[cube]
version = "1.13.1-r2"
provider = false
cluster-name = "cube-tc-gcp-cluster"
cluster-description = "This is test cluster"
cluster-type = "small"
cluster-id = "cube-tc-gcp-cluster-id"
alert-language = "ko"


[kubenetes]
service-cidr = "10.96.0.0/12"
pod-cidr = "10.10.0.0/16"

  [kubenetes.etcd]
  ip = [
    "192.168.1.2",
    "192.168.1.3",
    "192.168.1.5",
    "192.168.1.6",
    "192.168.1.7"
  ]

[node-pool]
data-dir = "/data"

  [node-pool.provider]
  name = "gcp"
  location = "default"

  [node-pool.security]
  ssh-user-id = "cloud"
  private-key-path = "/root/cubetest/cert-ssh/cocktail-cube-tc-ssh.pem"
  key-path = "/root/cubetest/cert-ssh/cocktail-cube-tc-ssh.key"

  [node-pool.master]
  name = "master"
  ip = [
    "192.168.1.2",
    "192.168.1.3"
  ]
  loadbalancer-ip = ""
  ingress-host = ""
  node-port-url = ""
  node-portrange = "30000-32767"

  [[node-pool.nodes]]
  name = "default"
  ip = [
    "192.168.1.5",
    "192.168.1.6"
  ]

[enterprise-product]
install = true
release-name = "cocktail"
https = false
  [enterprise-product.cert-file]
  ssl-certificate = ""
  ssl-certificate-key = ""

[addon]
install = true

[shared-storage]
install = true
name = "shared"
storage-ip = "192.168.1.7"
storage-mount-dir = "/storage"
storage-volume-size = 100

[private-registry]
install = true
name = "harbor"
registry-ip = "192.168.1.7"
data-dir = "/data"
public-cert = false
  [private-registry.cert-file]
  ssl-certificate = ""
  ssl-certificate-key = ""
```

* 에러 내용

```
[root@cocktail-cube-tc-node-3 cubetest]# cube cluster update
No nodes are added or shrunk.
```

```
[root@cocktail-cube-tc-node-3 cubetest]# cube cluster update
   Pre-configure for cluster instances ... -

Got signal : terminated
   Pre-configure for cluster instances ... / [root@cocktail-cube-tc-node-3 cubetest]# cube cluster update
Get http://192.168.1.2:30000/api/cluster/v2/conditions?accountSeq=1&useK8s=true: dial tcp 192.168.1.2:30000: i/o timeout

업데이트 중간에 terminated 되면서 해당 node가 not ready가 되면 설정이 꼬인다. 
```

```
[cube]
version = "1.13.1-r2"
provider = false
cluster-name = "cube-tc-gcp-cluster"
cluster-description = "This is test cluster"
cluster-type = "small"
cluster-id = "cube-tc-gcp-cluster-id"
alert-language = "ko"


[kubenetes]
service-cidr = "10.96.0.0/12"
pod-cidr = "10.10.0.0/16"

  [kubenetes.etcd]
  ip = [
    "192.168.1.2",
    "192.168.1.3",
    "192.168.1.5",
    "192.168.1.6",
    "192.168.1.7"
  ]

[node-pool]
data-dir = "/data"

  [node-pool.provider]
  name = "gcp"
  location = "default"

  [node-pool.security]
  ssh-user-id = "cloud"
  private-key-path = "/root/cubetest/cert-ssh/cocktail-cube-tc-ssh.pem"
  key-path = "/root/cubetest/cert-ssh/cocktail-cube-tc-ssh.key"

  [node-pool.master]
  name = "master"
  ip = [
    "192.168.1.2",
    "192.168.1.3"
  ]
  loadbalancer-ip = ""
  ingress-host = ""
  node-port-url = ""
  node-portrange = "30000-32767"

  [[node-pool.nodes]]
  name = "default"
  ip = [
    "192.168.1.5",
    "192.168.1.6",
    "192.168.1.7"
  ]

[enterprise-product]
install = true
release-name = "cocktail"
https = false
  [enterprise-product.cert-file]
  ssl-certificate = ""
  ssl-certificate-key = ""

[addon]
install = true

[shared-storage]
install = true
name = "shared"
storage-ip = "192.168.1.7"
storage-mount-dir = "/storage"
storage-volume-size = 100

[private-registry]
install = true
name = "harbor"
registry-ip = "192.168.1.7"
data-dir = "/data"
public-cert = false
  [private-registry.cert-file]
  ssl-certificate = ""
  ssl-certificate-key = ""
```

### failed 확인 하는 방법은 무엇인가요?

```
2019-02-19 07:13:55 etcd-192.168.1.2           : ok=32   changed=12   unreachable=0    failed=0
2019-02-19 07:13:55 master-192.168.1.2         : ok=134  changed=68   unreachable=0    failed=0
2019-02-19 07:13:55 master-192.168.1.3         : ok=39   changed=12   unreachable=0    failed=1
2019-02-19 07:13:55 registry-192.168.1.7       : ok=31   changed=12   unreachable=0    failed=0
2019-02-19 07:13:55 storage-192.168.1.7        : ok=13   changed=6    unreachable=0    failed=0
2019-02-19 07:13:55 worker-192.168.1.5         : ok=65   changed=25   unreachable=0    failed=0
2019-02-19 07:13:55 worker-192.168.1.6         : ok=51   changed=24   unreachable=0    failed=0
2019-02-19 07:13:56 Error: Processing failed, check error message and try again.
```

* cluster-type = "small" 일때 마스터가 2대면 etcd 구성도 luster-type이 medium 을 따라간다.

```
etcd각 mast 개수 보다 작으면 fail
```

### 예외상황 체크 리스트 필요

1. master 2대 일때 lb 체크 필수 항목 이어야 한다.

2. master 2대 일때 etcd 3개 이상 체크 필요.

### WARNING 발생 문제

```
[root@cocktail-cube-tc-master-1 cubetest]# cube create
Setup cube cluster ...
[WARNING]: Found both group and host with same name: storage
[WARNING]: Found both group and host with same name: registry
```

* 원인 분석 :

```
[root@cocktail-cube-tc-master-1 cubetest]# docker exec -it cubepack /bin/bash
bash-4.4#
bash-4.4# cd ..
bash-4.4# cd cubescripts/inventories/
bash-4.4# cat inventory

# Inventory create by cube

master01 ansible_ssh_host=192.168.1.2 ip=192.168.1.2
master02 ansible_ssh_host=192.168.1.3 ip=192.168.1.3
worker01 ansible_ssh_host=192.168.1.6 ip=192.168.1.6
worker02 ansible_ssh_host=192.168.1.5 ip=192.168.1.5
etcd01 ansible_ssh_host=192.168.1.2 ip=192.168.1.2
etcd02 ansible_ssh_host=192.168.1.3 ip=192.168.1.3
etcd03 ansible_ssh_host=192.168.1.6 ip=192.168.1.6
registry ansible_ssh_host=192.168.1.7 ip=192.168.1.7
storage ansible_ssh_host=192.168.1.7 ip=192.168.1.7

[etcd]
etcd01
etcd02
etcd03

[etcd-private]
etcd01
etcd02
etcd03

[masters]
master01
master02

[sslhost]
master01

[node]
worker01
worker02

# 이름이 같으면 안된다.
[registry]
registry

[storage]
storage

```

안시블에서 대분류 이름 값이 같아서 나는 warning 메세지

#### 워닝이나 에러 발생후 cube destroy 면 한번에 지워지지 않는다.

```
2019-02-19 09:45:13 INFO: Uninstall cluster ...
2019-02-19 09:45:14
2019-02-19 09:45:14 TASK [reset : Stop etcd, kubelet services] *************************************
2019-02-19 09:45:14 changed: [worker02] => (item=kubelet)
2019-02-19 09:45:14 changed: [master02] => (item=kubelet)
2019-02-19 09:45:14 changed: [master01] => (item=kubelet)
2019-02-19 09:45:14 changed: [worker01] => (item=kubelet)
2019-02-19 09:45:14 ok: [worker02] => (item=etcd)
2019-02-19 09:45:15 changed: [master02] => (item=etcd)
2019-02-19 09:45:15 changed: [worker01] => (item=etcd)
2019-02-19 09:45:22 changed: [master01] => (item=etcd)





=================


2019-02-19 09:49:59 [WARNING]: Found both group and host with same name: storage
2019-02-19 09:49:59 [WARNING]: Found both group and host with same name: registry
2019-02-19 09:50:00
2019-02-19 09:50:00 PLAY [masters:node] ************************************************************
2019-02-19 09:50:02
2019-02-19 09:50:02 TASK [Gathering Facts] *********************************************************
2019-02-19 09:50:02 ok: [worker01]
2019-02-19 09:50:02 ok: [worker02]
2019-02-19 09:50:02 ok: [master02]
2019-02-19 09:50:02 ok: [master01]
2019-02-19 09:50:02
2019-02-19 09:50:02 TASK [reset : debug] ***********************************************************
2019-02-19 09:50:02 ok: [master01] =>
2019-02-19 09:50:02 msg: |-
2019-02-19 09:50:02 INFO: Uninstall cluster ...
2019-02-19 09:50:03
2019-02-19 09:50:03 TASK [reset : Stop etcd, kubelet services] *************************************
2019-02-19 09:50:03 ok: [worker02] => (item=kubelet)
2019-02-19 09:50:03 ok: [worker01] => (item=kubelet)
2019-02-19 09:50:03 ok: [master02] => (item=kubelet)
2019-02-19 09:50:03 ok: [master01] => (item=kubelet)
2019-02-19 09:50:03 ok: [worker02] => (item=etcd)
2019-02-19 09:50:03 ok: [worker01] => (item=etcd)
2019-02-19 09:50:03 ok: [master02] => (item=etcd)
2019-02-19 09:50:03 ok: [master01] => (item=etcd)
2019-02-19 09:50:04
2019-02-19 09:50:04 TASK [reset : Remove all containers] *******************************************
2019-02-19 09:50:04 changed: [worker02]
2019-02-19 09:50:04 changed: [worker01]
2019-02-19 09:50:04 changed: [master02]
```